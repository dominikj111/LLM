{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790d2e29-d4e4-4971-a2b6-85c3b394820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cowsay\n",
      "  Using cached cowsay-6.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Using cached cowsay-6.1-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: cowsay\n",
      "Successfully installed cowsay-6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "  _____________________________\n",
      "| Hello from installed package! |\n",
      "  =============================\n",
      "                             \\\n",
      "                              \\\n",
      "                                ^__^\n",
      "                                (oo)\\_______\n",
      "                                (__)\\       )\\/\\\n",
      "                                    ||----w |\n",
      "                                    ||     ||\n"
     ]
    }
   ],
   "source": [
    "!/opt/miniconda3/bin/pip install cowsay\n",
    "import cowsay\n",
    "cowsay.cow('Hello from installed package!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71819e38-06eb-47f9-a614-6893c1aa2e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/opt/miniconda3/lib/python3.12/site-packages/ctransformers/lib/basic/libctransformers.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model with absolute path\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tinyllama-1.1b-chat-v0.3.Q2_K.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# make sure this path is correct\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# explicitly use CPU\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Sample text\u001b[39;00m\n\u001b[1;32m     13\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, how are you today?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ctransformers/hub.py:175\u001b[0m, in \u001b[0;36mAutoModelForCausalLM.from_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    168\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_find_model_path_from_repo(\n\u001b[1;32m    169\u001b[0m         model_path_or_repo_id,\n\u001b[1;32m    170\u001b[0m         model_file,\n\u001b[1;32m    171\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    172\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    173\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ctransformers/llm.py:246\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model_path, model_type, config, lib)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to detect model type. Please specify a model type using:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  AutoModelForCausalLM.from_pretrained(..., model_type=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         )\n\u001b[1;32m    244\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgguf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib \u001b[38;5;241m=\u001b[39m \u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lib\u001b[38;5;241m.\u001b[39mctransformers_llm_create(\n\u001b[1;32m    248\u001b[0m     model_path\u001b[38;5;241m.\u001b[39mencode(),\n\u001b[1;32m    249\u001b[0m     model_type\u001b[38;5;241m.\u001b[39mencode(),\n\u001b[1;32m    250\u001b[0m     config\u001b[38;5;241m.\u001b[39mto_struct(),\n\u001b[1;32m    251\u001b[0m )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ctransformers/llm.py:126\u001b[0m, in \u001b[0;36mload_library\u001b[0;34m(path, gpu)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m    125\u001b[0m     load_cuda()\n\u001b[0;32m--> 126\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m lib\u001b[38;5;241m.\u001b[39mctransformers_llm_create\u001b[38;5;241m.\u001b[39margtypes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    129\u001b[0m     c_char_p,  \u001b[38;5;66;03m# model_path\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     c_char_p,  \u001b[38;5;66;03m# model_type\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     ConfigStruct,  \u001b[38;5;66;03m# config\u001b[39;00m\n\u001b[1;32m    132\u001b[0m ]\n\u001b[1;32m    133\u001b[0m lib\u001b[38;5;241m.\u001b[39mctransformers_llm_create\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m llm_p\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/ctypes/__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/miniconda3/lib/python3.12/site-packages/ctransformers/lib/basic/libctransformers.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the model\n",
    "model_path = \"./tinyllama-1.1b-chat-v0.3.Q2_K.gguf\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    model_type=\"llama\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# Sample text\n",
    "text = \"Hello, how are you today?\"\n",
    "generated_text = llm(text, max_new_tokens=50, temperature=0.7)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346d66d-ac24-4060-bc74-4810dd45d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
